# Load scikit-learn's datasets
from sqlalchemy import create_engine
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.datasets import make_classification
from sklearn.datasets import make_regression
from sklearn import datasets

# Load digits dataset
digits = datasets.load_digits()

# Create features matrix
features = digits.data

# Create target vector
target = digits.target

# View first observation
features[0]

print('When we want a dataset designed to be used with linear regression, make_regression is a good choice:')
# Load library
#from sklearn.datasets import make_regression

# Generate features matrix, target vector, and the true coefficients
features, target, coefficients = make_regression(n_samples=100,
                                                 n_features=3,
                                                 n_informative=3,
                                                 n_targets=1,
                                                 noise=0.0,
                                                 coef=True,
                                                 random_state=1)

# View feature matrix and target vector
print('Feature Matrix\n', features[:3])
print('Target Vector\n', target[:3])

print('If we are interested in creating a simulated dataset for classification, we can use make_classification:')
# Load library
#from sklearn.datasets import make_classification

# Generate features matrix and target vector
features, target = make_classification(n_samples=100,
                                       n_features=3,
                                       n_informative=3,
                                       n_redundant=0,
                                       n_classes=2,
                                       weights=[.25, .75],
                                       random_state=1)

# View feature matrix and target vector
print('Feature Matrix\n', features[:3])
print('Target Vector\n', target[:3])

print('Finally, if we want a dataset designed to work well with clustering techniques, scikit-learn offers make_blobs:')
# Load library
# from sklearn.datasets import make_blobs

# Generate feature matrix and target vector
features, target = make_blobs(n_samples=100,
                              n_features=2,
                              centers=3,
                              cluster_std=0.5,
                              shuffle=True,
                              random_state=1)

# View feature matrix and target vector
print('Feature Matrix\n', features[:3])
print('Target Vector\n', target[:3])

""" As might be apparent from the solutions, make_regression returns a feature matrix of float values and a target vector of float values,
while make_classification and make_blobs return a feature matrix of
float values and a target vector of integers representing membership in
a class.

scikit-learn’s simulated datasets offer extensive options to control
the type of data generated. scikit-learn’s documentation contains a full
description of all the parameters, but a few are worth noting.

In make_regression and make_classification, n_informative
determines the number of features that are used to generate the target
vector. If n_informative is less than the total number of features
(n_features), the resulting dataset will have redundant features
that can be identified through feature selection techniques.

In addition, make_classification contains a weights parameter that allows us to simulate datasets with imbalanced classes. For example,
weights = [.25, .75] would return a dataset with 25% of observations belonging to one class and 75% of observations belonging to a second
class.

For make_blobs, the centers parameter determines the number of
clusters generated. Using the matplotlib visualization library, we can
visualize the clusters generated by make_blobs: """

# Load library
#import matplotlib.pyplot as plt

# View scatterplot
plt.scatter(features[:, 0], features[:, 1], c=target)
plt.show()

# Loading a CSV File
# Load library
#import pandas as pd

# Create URL
url = 'https://raw.githubusercontent.com/chrisalbon/sim_data/master/data.csv'

# Load dataset
dataframe = pd.read_csv(url)

# View first two rows
dataframe.head(2)

# Use the pandas library’s read_excel to load an Excel spreadsheet:
# Load library
#import pandas as pd

# Create URL
url = 'https://raw.githubusercontent.com/chrisalbon/sim_data/master/data.xlsx'

# Load data
dataframe = pd.read_excel(url, sheet_name=0, header=1)

# View the first two rows
dataframe.head(2)

# The pandas library provides read_json to convert a JSON file into a pandas object:

# Load library

# Create URL
url = 'https://raw.githubusercontent.com/chrisalbon/sim_data/master/data.json'

# Load data
dataframe = pd.read_json(url, orient='columns')

# View the first two rows
dataframe.head(2)

# pandas’ read_sql_query allows us to make a SQL query to a database and load it:

# Load libraries
#import pandas as pd
#from sqlalchemy import create_engine

# Create a connection to the database
#database_connection = create_engine('sqlite:///sample.db')

# Load data
#dataframe = pd.read_sql_query('SELECT * FROM data', database_connection)

# View first two rows
#dataframe.head(2)
